{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:29.300906Z",
     "start_time": "2024-10-06T19:05:29.299093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 0.31482218 'lr': 0.001\n",
    "# 0.10198582 'lr': 0.0001 almost | all predictions are 0.5\n",
    "# 0.26362439 'lr': 0.001 augmentations | all predictions are 0.5\n",
    "# 0.24052888 'lr': 0.001 augmentations x 10 | not bad RMSE: 7063.950251422128 18.00782954549693 %\n",
    "# 0.33602387 'lr': 0.001 batch_size 32 batchnorm augmentations x 10 | some shit RMSE: 24987.223981126954 64.59238449281463 %"
   ],
   "id": "a97d9148e1697134",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5aed08ff-db7b-48f2-807a-b734b5656ebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:30.892029Z",
     "start_time": "2024-10-06T19:05:29.586243Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from typing import Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "import obspy\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly import graph_objects as go"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e4a360e8444336e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:30.896808Z",
     "start_time": "2024-10-06T19:05:30.892888Z"
    }
   },
   "source": [
    "def make_deterministic(seed: int = 0):\n",
    "    \"\"\"\n",
    "    Make results deterministic.\n",
    "    If seed == -1, do not make deterministic.\n",
    "    Running the script in a deterministic way might slow it down.\n",
    "    \"\"\"\n",
    "    if seed == -1:\n",
    "        return\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def create_spectrogram(st: obspy.core.stream.Stream, minfreq: float = None, maxfreq: float = None, shape=(129, 2555)) -> np.ndarray:\n",
    "    st_filt = st.copy()\n",
    "\n",
    "    if minfreq is not None and maxfreq is not None:\n",
    "        st_filt.filter('bandpass', freqmin=minfreq, freqmax=maxfreq)\n",
    "\n",
    "    tr_filt = st_filt.traces[0].copy()\n",
    "    tr_data_filt = tr_filt.data\n",
    "\n",
    "    _, _, spectrogram = signal.spectrogram(tr_data_filt, tr_filt.stats.sampling_rate)\n",
    "\n",
    "    # Normalize\n",
    "    spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min())\n",
    "\n",
    "    current_shape = spectrogram.shape\n",
    "    padded_spectrogram = np.zeros(shape, dtype=np.float64)\n",
    "    min_rows = min(current_shape[0], shape[0])\n",
    "    min_cols = min(current_shape[1], shape[1])\n",
    "    padded_spectrogram[:min_rows, :min_cols] = spectrogram[:min_rows, :min_cols]\n",
    "\n",
    "    return padded_spectrogram.astype(np.float64)\n",
    "\n",
    "def create_label(st: obspy.core.stream.Stream, row: pd.Series) -> float:\n",
    "    # Start time of trace (another way to get the relative arrival time using datetime)\n",
    "    arrival = row['time_rel(sec)']\n",
    "    starttime = st.traces[0].stats.starttime.datetime\n",
    "    total = (st.traces[0].stats.endtime.datetime - starttime).total_seconds()\n",
    "    \n",
    "    return arrival / total\n",
    "\n",
    "def create_sample(row, minfreq: float = None, maxfreq: float = None) -> Tuple[np.ndarray, float]:\n",
    "    test_filename = row.filename\n",
    "    st = obspy.read(f'{data_directory}{test_filename}.mseed')\n",
    "    \n",
    "    return create_spectrogram(st, minfreq, maxfreq), create_label(st, row)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4f7b59be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:32.100121Z",
     "start_time": "2024-10-06T19:05:30.897163Z"
    }
   },
   "source": [
    "data_directory = './data/lunar/training/data/S12_GradeA/'\n",
    "categories_df = pd.read_csv('./data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv')\n",
    "\n",
    "labels = []\n",
    "samples = []\n",
    "for index in range(len(categories_df)):\n",
    "    row = categories_df.iloc[index]\n",
    "    spectrogram, label = create_sample(row, 0.001, 1.0)\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    spectrogram_path = os.path.join('./data/lunar/training/spectrograms/', row[\"filename\"])\n",
    "    np.savez(spectrogram_path, spectrogram)\n",
    "    \n",
    "    labels.append(label)\n",
    "    samples.append(spectrogram)\n",
    "    \n",
    "df = pd.DataFrame({'filename': categories_df.filename, 'label': labels})\n",
    "df = pd.concat([df, categories_df[[\"mq_type\", \"evid\", \"time_rel(sec)\"]]], axis=1)\n",
    "\n",
    "df.to_csv('./data/lunar/training/spectrograms.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:32.107569Z",
     "start_time": "2024-10-06T19:05:32.100920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ComposeWithLabels:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample)\n",
    "        return sample\n",
    "\n",
    "class RandomApplyWithLabels:\n",
    "    def __init__(self, transform, p=0.5):\n",
    "        self.transform = transform\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if torch.rand(1).item() < self.p:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "class RandomTimeShift:\n",
    "    \"\"\"\n",
    "    Shifts the spectrogram in the time dimension by a random amount.\n",
    "    Also adjusts the time label accordingly.\n",
    "    \"\"\"\n",
    "    def __init__(self, shift_range):\n",
    "        self.shift_range = shift_range\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        spectrogram = sample['spectrogram']\n",
    "        label = sample['label']\n",
    "\n",
    "        shift = np.random.randint(-self.shift_range, self.shift_range)\n",
    "        total_time_steps = spectrogram.shape[2]\n",
    "\n",
    "        if shift == 0:\n",
    "            pass  # No change needed\n",
    "        elif shift > 0:\n",
    "            # Shift to the right\n",
    "            padding = torch.zeros(spectrogram.shape[0], spectrogram.shape[1], shift)\n",
    "            spectrogram = torch.cat((padding, spectrogram[:, :, :-shift]), dim=2)\n",
    "        else:\n",
    "            # Shift to the left\n",
    "            shift = -shift\n",
    "            padding = torch.zeros(spectrogram.shape[0], spectrogram.shape[1], shift)\n",
    "            spectrogram = torch.cat((spectrogram[:, :, shift:], padding), dim=2)\n",
    "\n",
    "        # Adjust the label\n",
    "        label += (shift / total_time_steps)\n",
    "        label = torch.clamp(label, 0.0, 1.0)\n",
    "\n",
    "        sample['spectrogram'] = spectrogram\n",
    "        sample['label'] = label\n",
    "        return sample\n",
    "\n",
    "class RandomTimeMask:\n",
    "    def __init__(self, max_mask_size):\n",
    "        self.max_mask_size = max_mask_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        spectrogram = sample['spectrogram']\n",
    "        _, _, t = spectrogram.shape\n",
    "        mask_size = np.random.randint(0, self.max_mask_size)\n",
    "        t0 = np.random.randint(0, t - mask_size)\n",
    "        spectrogram[:, :, t0:t0 + mask_size] = 0\n",
    "\n",
    "        sample['spectrogram'] = spectrogram\n",
    "        return sample\n",
    "\n",
    "class RandomFrequencyMask:\n",
    "    def __init__(self, max_mask_size):\n",
    "        self.max_mask_size = max_mask_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        spectrogram = sample['spectrogram']\n",
    "        _, f, _ = spectrogram.shape\n",
    "        mask_size = np.random.randint(0, self.max_mask_size)\n",
    "        f0 = np.random.randint(0, f - mask_size)\n",
    "        spectrogram[:, f0:f0 + mask_size, :] = 0\n",
    "\n",
    "        sample['spectrogram'] = spectrogram\n",
    "        return sample\n",
    "\n",
    "class AddNoise:\n",
    "    def __init__(self, noise_level=0.005):\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        spectrogram = sample['spectrogram']\n",
    "        noise = torch.randn_like(spectrogram) * self.noise_level\n",
    "        spectrogram = spectrogram + noise\n",
    "\n",
    "        sample['spectrogram'] = spectrogram\n",
    "        return sample\n",
    "\n",
    "class AmplitudeScaling:\n",
    "    def __init__(self, scale_range=(0.8, 1.2)):\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        spectrogram = sample['spectrogram']\n",
    "        scale = np.random.uniform(*self.scale_range)\n",
    "        spectrogram = spectrogram * scale\n",
    "\n",
    "        sample['spectrogram'] = spectrogram\n",
    "        return sample\n",
    "    \n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "class RandomSpikeAugmentation:\n",
    "    def __init__(self, base_spike_value=1.0, spike_duration=1, max_num_spikes=3, fade_factor=0.8, noise_level=0.25, size=4, sigma=1):\n",
    "        \"\"\"\n",
    "        Adds N random spikes to the spectrogram with discrete steps, noise, and frequency fade,\n",
    "        and applies a Gaussian filter to smooth the spikes.\n",
    "        \n",
    "        :param base_spike_value: The base value of the spike.\n",
    "        :param spike_duration: Duration of each spike in time steps.\n",
    "        :param max_num_spikes: Number of spikes to add.\n",
    "        :param fade_factor: Factor by which the spike fades at higher frequencies.\n",
    "        :param noise_level: The amount of random noise to add to the spike.\n",
    "        :param size: Defines which portion of frequencies will be affected.\n",
    "        :param sigma: Standard deviation for Gaussian filter.\n",
    "        \"\"\"\n",
    "        self.base_spike_value = base_spike_value\n",
    "        self.spike_duration = spike_duration\n",
    "        self.max_num_spikes = max_num_spikes\n",
    "        self.fade_factor = fade_factor\n",
    "        self.noise_level = noise_level\n",
    "        self.size = size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        spectrogram = sample['spectrogram']\n",
    "        _, f, t = spectrogram.shape\n",
    "        \n",
    "        num_spikes = np.random.randint(1, self.max_num_spikes) if self.max_num_spikes > 1 else 1\n",
    "        \n",
    "        for _ in range(num_spikes):\n",
    "            # Randomly select the start time for the spike\n",
    "            spike_start = np.random.randint(0, t - self.spike_duration)\n",
    "            \n",
    "            # Create a spike that fades at higher frequencies and has some discrete steps\n",
    "            for i in range(int(f * (1 / self.size))):  # Iterate over first 1/size of frequencies\n",
    "                # Compute the fade factor for the current frequency\n",
    "                fade = self.fade_factor ** i\n",
    "                \n",
    "                # Create a spike with noise and discrete steps\n",
    "                spike_value = self.base_spike_value * fade + (np.random.randn() * self.noise_level)\n",
    "                spike = torch.ones(self.spike_duration) * spike_value\n",
    "                spike = torch.clamp(spike, 0.0, 1.0)\n",
    "                \n",
    "                # Apply the spike to the spectrogram at the current frequency\n",
    "                spectrogram[:, i, spike_start:spike_start + self.spike_duration] += spike\n",
    "\n",
    "        # Convert the spectrogram to numpy for applying the gaussian filter\n",
    "        spectrogram_np = spectrogram.numpy()\n",
    "\n",
    "        # Apply Gaussian filter to smooth the spikes\n",
    "        spectrogram_np = gaussian_filter(spectrogram_np, sigma=self.sigma)\n",
    "\n",
    "        # Convert back to torch tensor\n",
    "        sample['spectrogram'] = torch.tensor(spectrogram_np)\n",
    "\n",
    "        return sample"
   ],
   "id": "162b4fbd7d0b5c8e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "5dedd690dcff8cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:32.111030Z",
     "start_time": "2024-10-06T19:05:32.107932Z"
    }
   },
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, sample: float = 1.0, transform=None, augmentations=False):\n",
    "        self.samples_df = dataframe.sample(frac=sample, replace=False if sample == 1.0 else True)\n",
    "        self.samples_df = self.samples_df.sort_values(\n",
    "            by='evid',\n",
    "            key=lambda x: x.str.extract('(\\d+)$').iloc[:, 0].astype(int)\n",
    "        )\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "        if self.augmentations:\n",
    "            self.augmentation_transforms = ComposeWithLabels([\n",
    "                RandomApplyWithLabels(RandomTimeShift(shift_range=20), p=1.0),\n",
    "                RandomApplyWithLabels(RandomTimeMask(max_mask_size=50), p=1.0),\n",
    "                RandomApplyWithLabels(RandomFrequencyMask(max_mask_size=2), p=0.5),\n",
    "                RandomApplyWithLabels(AddNoise(noise_level=0.0075), p=1.0),\n",
    "                RandomApplyWithLabels(AmplitudeScaling(scale_range=(0.8, 1.2)), p=1.0),\n",
    "                RandomApplyWithLabels(RandomSpikeAugmentation(size=4, max_num_spikes=2), p=1.0),\n",
    "                RandomApplyWithLabels(RandomSpikeAugmentation(size=2, max_num_spikes=1), p=1.0),\n",
    "            ])\n",
    "        else:\n",
    "            self.augmentation_transforms = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        row = self.samples_df.iloc[idx]\n",
    "        spectrogram = np.load(f'./data/lunar/training/spectrograms/{row.filename}.npz')['arr_0']\n",
    "        label = torch.tensor(row.label, dtype=torch.float64)\n",
    "        \n",
    "        if self.transform:\n",
    "            spectrogram = self.transform(spectrogram)\n",
    "            \n",
    "        sample = {'spectrogram': spectrogram, 'label': label}\n",
    "\n",
    "        if self.augmentation_transforms:\n",
    "            sample = self.augmentation_transforms(sample)\n",
    "        \n",
    "        return sample['spectrogram'].double(), sample['label'].double()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a3619af74de1f6f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:32.114091Z",
     "start_time": "2024-10-06T19:05:32.111439Z"
    }
   },
   "source": [
    "class SeismicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SeismicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 319, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 16 * 319)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path, weights_only=False))\n",
    "        self.eval()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e646cdc942fe4071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:32.119632Z",
     "start_time": "2024-10-06T19:05:32.114468Z"
    }
   },
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_fn,\n",
    "        dataset_fn,\n",
    "        dataframe,\n",
    "        criterion,\n",
    "        optimizer_fn,\n",
    "        shuffle=True,\n",
    "    ):\n",
    "        self.model = None\n",
    "        self.model_fn = model_fn\n",
    "        self.dataset_fn = dataset_fn\n",
    "        self.dataframe = dataframe\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_fn = optimizer_fn\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = None\n",
    "        self.batch_size = None\n",
    "        self.k_folds = None\n",
    "        self.optimizer_params = None\n",
    "\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model_state = None\n",
    "        self.best_hyperparams = None\n",
    "        \n",
    "        make_deterministic(42)\n",
    "\n",
    "    def train_cross_validation(self, optimizer_params, num_epochs=1, batch_size=16, k_folds=5):\n",
    "        self.optimizer_params = optimizer_params\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.k_folds = k_folds\n",
    "        \n",
    "        # K-fold cross-validation\n",
    "        indices = list(range(len(self.dataframe)))\n",
    "        kf = KFold(n_splits=self.k_folds, shuffle=self.shuffle)\n",
    "        mean_val_loss = 0.0\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "            print(f'Fold {fold+1}/{self.k_folds}')\n",
    "            # Create data loaders\n",
    "            train_subset = self.dataset_fn(dataframe=self.dataframe.iloc[train_idx], sample=10.0, augmentations=True)\n",
    "            val_subset = self.dataset_fn(dataframe=self.dataframe.iloc[val_idx], sample=1, augmentations=False)\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                train_subset, batch_size=self.batch_size, shuffle=True\n",
    "            )\n",
    "            val_loader = DataLoader(\n",
    "                val_subset, batch_size=self.batch_size, shuffle=False\n",
    "            )\n",
    "\n",
    "            # Initialize model and optimizer for this fold\n",
    "            self.model = self.model_fn()\n",
    "            self.model.train()\n",
    "            optimizer = self.optimizer_fn(\n",
    "                self.model.parameters(), **self.optimizer_params\n",
    "            )\n",
    "\n",
    "            self._train_model(train_loader, optimizer)\n",
    "            val_loss = self._evaluate_model(val_loader)\n",
    "            mean_val_loss += val_loss\n",
    "            print(f'Validation Loss for fold {fold+1}: {val_loss:.8f}')\n",
    "\n",
    "        mean_val_loss /= self.k_folds\n",
    "        print(f'Mean Validation Loss: {mean_val_loss:.8f}')\n",
    "        \n",
    "        # Check for best model\n",
    "        if mean_val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = mean_val_loss\n",
    "            self.best_model_state = self.model.state_dict()\n",
    "            self.best_hyperparams = {\n",
    "                'learning_rate': self.optimizer_params.get('lr', None),\n",
    "                'batch_size': self.batch_size,\n",
    "                'num_epochs': self.num_epochs,\n",
    "            }\n",
    "\n",
    "        print('Cross validation training complete')\n",
    "        print(self.best_hyperparams)\n",
    "        \n",
    "    def train(self, epochs, batch_size, optimizer_params, augmentations=True):\n",
    "        self.num_epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer_params = optimizer_params\n",
    "        dataset = self.dataset_fn(dataframe=self.dataframe, sample=10.0, augmentations=augmentations)\n",
    "        train_loader = DataLoader(\n",
    "            dataset, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        self.model = self.model_fn()\n",
    "        self.model.train()\n",
    "        optimizer = self.optimizer_fn(\n",
    "            self.model.parameters(), **self.optimizer_params\n",
    "        )\n",
    "        self._train_model(train_loader, optimizer)\n",
    "        train_loss = self._evaluate_model(\n",
    "            DataLoader(\n",
    "            self.dataset_fn(dataframe=self.dataframe, sample=1, augmentations=augmentations), batch_size=self.batch_size, shuffle=False\n",
    "\t\t    )\n",
    "        )\n",
    "        print(f'Training Loss: {train_loss:.8f}')\n",
    "\n",
    "    def _train_model(self, train_loader, optimizer):\n",
    "        self.model.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            running_loss = 0.0\n",
    "            with tqdm(\n",
    "                train_loader,\n",
    "                desc=f'Epoch [{epoch+1}/{self.num_epochs}]',\n",
    "                unit='batch',\n",
    "            ) as batch_bar:\n",
    "                for spectrograms, labels in batch_bar:\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = self.model(spectrograms)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                    batch_bar.set_postfix(loss=loss.item())\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            print(f\"Epoch [{epoch+1}/{self.num_epochs}], Loss: {avg_loss:.8f}\")\n",
    "\n",
    "    def _evaluate_model(self, val_loader):\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for spectrograms, labels in val_loader:\n",
    "                labels = labels.unsqueeze(1)\n",
    "                outputs = self.model(spectrograms)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        return avg_val_loss\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a05de5bbe698812a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:32.122037Z",
     "start_time": "2024-10-06T19:05:32.119949Z"
    }
   },
   "source": [
    "def model_fn():\n",
    "    return SeismicCNN()\n",
    "\n",
    "def dataset_fn(dataframe, sample, augmentations):\n",
    "    return SpectrogramDataset(dataframe=dataframe, sample=sample, augmentations=augmentations)\n",
    "\n",
    "def optimizer_fn(params, lr):\n",
    "    return optim.Adam(params, lr=lr)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "4fe30adc712ea7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:32.125491Z",
     "start_time": "2024-10-06T19:05:32.122375Z"
    }
   },
   "source": [
    "def inference(model, dataset, save_folder, save_images=True):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    os.makedirs(f'{save_folder}/plots', exist_ok=True)\n",
    "\n",
    "    fnames = []\n",
    "    detection_times = []\n",
    "    relative_times = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for index in range(len(dataset)):\n",
    "        spectrogram, label = dataset[index]\n",
    "        test_filename = dataset.samples_df.iloc[index].filename\n",
    "        tr = obspy.read(f'{data_directory}{test_filename}.mseed')[0]\n",
    "        tr_data = tr.data\n",
    "        tr_times = tr.times()\n",
    "        starttime = tr.stats.starttime.datetime\n",
    "        endtime = tr.stats.endtime.datetime\n",
    "        total_seconds = (endtime - starttime).total_seconds()\n",
    "\n",
    "        prediction = model(spectrogram).item()\n",
    "        relative_time = prediction * total_seconds\n",
    "        \n",
    "        sampled_time = int(relative_time * tr.stats.sampling_rate)\n",
    "        true = int(dataset.samples_df.iloc[index]['time_rel(sec)'] * tr.stats.sampling_rate)\n",
    "\n",
    "        on_time = starttime + pd.Timedelta(seconds=relative_time)\n",
    "        on_time_str = datetime.strftime(on_time, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "        fnames.append(test_filename)\n",
    "        detection_times.append(on_time_str)\n",
    "        relative_times.append(relative_time)\n",
    "\n",
    "        if save_images:\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=tr_times, y=tr_data, mode='lines', name='Seismogram'\n",
    "            ))\n",
    "            fig.add_vline(x=tr_times[sampled_time], line=dict(color='red'), annotation_text=\"Trig. On\", annotation_position=\"top left\")\n",
    "            fig.add_vline(x=tr_times[true], line=dict(color='blue'), annotation_text=\"True\", annotation_position=\"top left\")\n",
    "\n",
    "            # Customize the layout\n",
    "            fig.update_layout(\n",
    "                title=\"Seismogram with STA/LTA Triggers\",\n",
    "                xaxis_title=\"Time (s)\",\n",
    "                yaxis_title=\"Amplitude\",\n",
    "                xaxis_range=[min(tr_times), max(tr_times)],\n",
    "                height=400,\n",
    "                width=900\n",
    "            )\n",
    "            fig.write_image(os.path.join(f'{save_folder}/plots/{test_filename}.png'))\n",
    "\n",
    "    detect_df = pd.DataFrame(data = {\n",
    "        'filename':fnames,\n",
    "        'time_abs(%Y-%m-%dT%H:%M:%S.%f)':detection_times,\n",
    "        'time_rel(sec)': relative_times,\n",
    "        \"evid\": dataset.samples_df['evid']\n",
    "    })\n",
    "    \n",
    "    detect_df = detect_df.sort_values(\n",
    "        by='evid',\n",
    "        key=lambda x: x.str.extract('(\\d+)$').iloc[:, 0].astype(int)\n",
    "    )\n",
    "    detect_df.to_csv(f'{save_folder}/catalog.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:35.635182Z",
     "start_time": "2024-10-06T19:05:32.588004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SeismicCNN()\n",
    "model.load('./data/lunar/models/seismic_activity_cnn_best.pth')\n",
    "dataframe = pd.read_csv('./data/lunar/training/spectrograms.csv')\n",
    "\n",
    "test_dataset = SpectrogramDataset(dataframe, augmentations=False)\n",
    "inference(model, test_dataset, save_folder='./data/lunar/cnn', save_images=False)"
   ],
   "id": "c7250fbe03cf41ae",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T19:05:35.638539Z",
     "start_time": "2024-10-06T19:05:35.635733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(f'./data/lunar/cnn/catalog.csv')\n",
    "mse = mean_squared_error(df['time_rel(sec)'], categories_df['time_rel(sec)'])\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f\"{rmse / categories_df['time_rel(sec)'].mean() * 100} %\")"
   ],
   "id": "896f088b989f24fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6575.2926625297505\n",
      "16.99723955456973 %\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T16:58:38.842622Z",
     "start_time": "2024-10-06T16:58:38.841224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# \n",
    "# k_folds = 5 \n",
    "# batch_size = len(dataframe) // k_folds\n",
    "# trainer = Trainer(\n",
    "#     model_fn=model_fn,\n",
    "#     dataset_fn=dataset_fn,\n",
    "#     dataframe=dataframe,\n",
    "#     criterion=criterion,\n",
    "#     optimizer_fn=optimizer_fn,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "# trainer.train_cross_validation(  \n",
    "#     optimizer_params={'lr': 0.001},\n",
    "#     num_epochs=5,\n",
    "#     batch_size=batch_size,\n",
    "#     k_folds=k_folds\n",
    "# )\n",
    "# trainer.train(epochs=10, batch_size=batch_size, optimizer_params={'lr': 0.001})\n",
    "# trainer.save_model('./data/lunar/models/seismic_activity_cnn_best.pth')"
   ],
   "id": "60de253d75b7b5d6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Pretty plot of errors\n",
    "# \n",
    "# sorted_df = pd.DataFrame({'time_rel_true': categories_df['time_rel(sec)'], 'time_rel_pred': df['time_rel(sec)']})\n",
    "# sorted_df = sorted_df.sort_values(by='time_rel_true')\n",
    "# \n",
    "# # Creating the figure\n",
    "# fig = go.Figure()\n",
    "# \n",
    "# # Add a filled line plot\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=sorted_df['time_rel_true'],\n",
    "#     y=sorted_df['time_rel_pred'],\n",
    "#     mode='lines',\n",
    "#     fill='tozeroy',  # Fills to the x-axis\n",
    "#     line=dict(color='rgba(138, 43, 226, 0.6)', width=2),  # Purple line with some transparency\n",
    "# ))\n",
    "# \n",
    "# # Update the layout to match the provided aesthetic\n",
    "# fig.update_layout(\n",
    "#     title=\"True vs Predicted Relative Times\",\n",
    "#     xaxis_title=\"True Relative Time (s)\",\n",
    "#     yaxis_title=\"Predicted Relative Time (s)\",\n",
    "#     height=1200,\n",
    "#     width=3000,\n",
    "#     paper_bgcolor='rgba(0,0,0,0)',  # Set the background to be transparent (dark theme)\n",
    "#     plot_bgcolor='rgba(10,10,30,0.8)',  # Dark blue background color for the plot area\n",
    "#     xaxis=dict(\n",
    "#         showgrid=False,  # Hide gridlines\n",
    "#         color='white'  # X-axis label color\n",
    "#     ),\n",
    "#     yaxis=dict(\n",
    "#         showgrid=True,\n",
    "#         gridcolor='rgba(255,255,255,0.1)',  # Light gridlines to match the aesthetic\n",
    "#         color='white'  # Y-axis label color\n",
    "#     ),\n",
    "#     font=dict(\n",
    "#         color=\"white\"  # General font color for the title, axes, etc.\n",
    "#     )\n",
    "# )\n",
    "# # font size\n",
    "# fig.update_layout(\n",
    "#     font=dict(\n",
    "#         size=32\n",
    "#     )\n",
    "# )\n",
    "# \n",
    "# fig.show()\n",
    "# fig.write_image('./data/cnn/true_vs_predicted.png')"
   ],
   "id": "cfa7de850f50cf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataset = SpectrogramDataset(dataframe, augmentations=True)\n",
    "# \n",
    "# def show_sample(dataset, index):\n",
    "#     dataset_sample = dataset[index][0][0]\n",
    "# \n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Heatmap(\n",
    "#         z=dataset_sample,\n",
    "#         colorscale='Viridis'\n",
    "#     ))\n",
    "#     fig.update_layout(\n",
    "#         title=\"Spectrogram Sample\",\n",
    "#         xaxis_title=\"Time (s)\",\n",
    "#         yaxis_title=\"Frequency (Hz)\",\n",
    "#         height=400,\n",
    "#         width=900\n",
    "#     )\n",
    "#     fig.show()\n",
    "# \n",
    "# show_sample(dataset, 15)"
   ],
   "id": "7030eafa97a78973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # There are samples where more than 1 quake has happened during the observation, we will convert them to separate samples\n",
    "# from obspy import UTCDateTime\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# #multiple_labels_indexes = [(31, 32), (67, 68), (107, 108), (150, 151)]\n",
    "# multiple_labels_indexes = [(10, 11)]\n",
    "# data_directory = './data/lunar/training/data/S12_GradeA/'\n",
    "# categories_df = pd.read_csv('./data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv')\n",
    "# \n",
    "# for pair in multiple_labels_indexes:\n",
    "#     first_row_index = categories_df[categories_df.evid == f\"evid{pair[0]:05d}\"].index[0]\n",
    "#     second_row_index = categories_df[categories_df.evid == f\"evid{pair[1]:05d}\"].index[0]\n",
    "# \n",
    "#     first_row = categories_df.loc[first_row_index]\n",
    "#     second_row = categories_df.loc[second_row_index]\n",
    "# \n",
    "#     buffer = 1000\n",
    "#     cut_time = UTCDateTime(second_row[\"time_abs(%Y-%m-%dT%H:%M:%S.%f)\"]) - buffer\n",
    "# \n",
    "#     first_st = obspy.read(f'{data_directory}{first_row.filename}.mseed')\n",
    "#     second_st = obspy.read(f'{data_directory}{second_row.filename}.mseed')\n",
    "# \n",
    "#     first_st = first_st.trim(endtime=cut_time)\n",
    "#     second_st = second_st.trim(starttime=cut_time)\n",
    "# \n",
    "#     first_st.write(f'{data_directory}{first_row.filename}.mseed', format=\"MSEED\")\n",
    "#     second_st.write(f'{data_directory}{second_row.filename}.mseed', format=\"MSEED\")\n",
    "# \n",
    "#     categories_df.loc[first_row_index, \"time_abs(%Y-%m-%dT%H:%M:%S.%f)\"] = first_st[0].stats.starttime.datetime.strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     categories_df.loc[second_row_index, \"time_abs(%Y-%m-%dT%H:%M:%S.%f)\"] = second_st[0].stats.starttime.datetime.strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     categories_df.loc[second_row_index, \"time_rel(sec)\"] = buffer\n",
    "# \n",
    "#     for data_cat, index in zip([first_st, second_st], [first_row_index, second_row_index]):\n",
    "#         arrival_time_rel = categories_df.iloc[index]['time_rel(sec)']\n",
    "# \n",
    "#         print(arrival_time_rel)\n",
    "# \n",
    "#         times = data_cat[0].times()\n",
    "#         data = data_cat[0].data\n",
    "#         # Plot the trace!\n",
    "#         fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "#         ax.plot(times,data)\n",
    "#         # Make the plot pretty\n",
    "#         ax.set_xlim([min(times),max(times)])\n",
    "#         ax.set_ylabel('Velocity (m/s)')\n",
    "#         ax.set_xlabel('Time (s)')\n",
    "#         # Plot where the arrival time is\n",
    "#         arrival_line = ax.axvline(x=arrival_time_rel, c='red', label='Rel. Arrival')\n",
    "#         ax.legend(handles=[arrival_line])\n",
    "# \n",
    "#         plt.show()\n",
    "# \n",
    "# categories_df.to_csv('./data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv', index=False)"
   ],
   "id": "c84757348920a647",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
